1. Adjusted Rand Index (ARI)
What it tells me:
Measures how well my clustering results match the true class labels, while correcting for random chance.

Range:
-1 (worst), 0 (random labeling), 1 (perfect match)
 Above 0.7 = Strong agreement

My Result (0.773):
My clusters closely match the true labels.
So, my clustering approach is meaningful and aligned with actual classes.

 2. Normalized Mutual Information (NMI)
What it tells me:
Checks how much information is shared between predicted clusters and actual class labels.

Range:
0 (no shared info) to 1 (perfect correlation)

My Result (0.728):
A lot of the structure in the true labels is captured by my clusters, even if label numbers differ.
This means the clustering follows similar patterns as the actual labels.

3. Silhouette Score
What it tells me:
Evaluates how well each point fits in its cluster vs. how far it is from other clusters.
In short — measures cluster tightness and separation.

Range:
-1 (bad), 0 (overlapping), 1 (ideal)
 ~0.5 = Good separation,
~0.3–0.4 = Some overlap

My Result (0.401):
My clusters are moderately well-separated, with some overlap.
Still a decent result for biological data like wheat seed varieties.

Summary Table
Score	                    Measures	                          What it Tells Me
ARI	            Match with true labels (adjusted)	      My clusters are aligned with actual classes
NMI            	Shared structure/information	          I captured the underlying label patterns
Silhouette	     Cluster cohesion + separation	          My clusters are compact, but slightly overlapping

# Linear SVM had similar scores on both training and testing sets (95%) this is a really great sign and it tells us that the model is generalizing well
and it is learning well

# Random Forest showed overfitting as it's accuracy score was a perfect 100% which is suspicious and it is a clear sign of overfitting.
Overfitting causes the model to perform well on the current data set but evaluating future data with this model won't give us accurate results
as the model memorizes the data instead of learning the patterns.
# IMP #

# Cross-validation helps identify the most reliable model — even if its test accuracy looks similar.
# Simplicity wins when data supports it.
# If your Linear SVM has both high train/test accuracy AND highest CV score, that’s your best model.

I learned how to measure different metrics such as ARI, NMI and Silhouette through this mini project. It was quite a fun project! I learned
alot through this and also identified my mistakes. I have a long road ahead and hoping to get better as i progress!
